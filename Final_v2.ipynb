{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # organize dataset into a useful structure\n",
    "# from os import makedirs\n",
    "# from os import listdir\n",
    "# from shutil import copyfile\n",
    "# from random import seed\n",
    "# from random import random\n",
    "# # create directories\n",
    "# dataset_home = './final-exam-data/data/kaggle_dogcat/'\n",
    "# subdirs = ['train/', 'test/']\n",
    "# for subdir in subdirs:\n",
    "# \t# create label subdirectories\n",
    "# \tlabeldirs = ['dogs/', 'cats/']\n",
    "# \tfor labldir in labeldirs:\n",
    "# \t\tnewdir = dataset_home + subdir + labldir\n",
    "# \t\tmakedirs(newdir, exist_ok=True)\n",
    "# # seed random number generator\n",
    "# seed(1)\n",
    "# # define ratio of pictures to use for validation\n",
    "# val_ratio = 0.25\n",
    "# # copy training dataset images into subdirectories\n",
    "# src_directory = 'train/'\n",
    "# for file in listdir(src_directory):\n",
    "# \tsrc = src_directory + '/' + file\n",
    "# \tdst_dir = 'train/'\n",
    "# \tif random() < val_ratio:\n",
    "# \t\tdst_dir = 'test/'\n",
    "# \tif file.startswith('cat'):\n",
    "# \t\tdst = dataset_home + dst_dir + 'cats/'  + file\n",
    "# \t\tcopyfile(src, dst)\n",
    "# \telif file.startswith('dog'):\n",
    "# \t\tdst = dataset_home + dst_dir + 'dogs/'  + file\n",
    "# \t\tcopyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 2 classes.\n",
      "Found 117 images belonging to 2 classes.\n",
      "> 100.000\n",
      "Found 400 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Julian\\Anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\dataframe_iterator.py:273: UserWarning: Found 2 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_5 to have shape (224, 224, 3) but got array with shape (128, 128, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-69b6a9eedc0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;31m# entry point, run the test harness\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m \u001b[0mrun_test_harness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-69b6a9eedc0c>\u001b[0m in \u001b[0;36mrun_test_harness\u001b[1;34m()\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     )\n\u001b[1;32m---> 91\u001b[1;33m     \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnb_samples\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;31m# learning curves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[1;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m   1520\u001b[0m             \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1521\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1522\u001b[1;33m             verbose=verbose)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[1;34m(model, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m    451\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m             \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m             \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[0mNumpy\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mof\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m         \"\"\"\n\u001b[1;32m-> 1268\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1269\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1270\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    136\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected input_5 to have shape (224, 224, 3) but got array with shape (128, 128, 3)"
     ]
    }
   ],
   "source": [
    "# baseline model with dropout for the dogs vs cats dataset\n",
    "# vgg16 model used for transfer learning on the dogs and cats dataset\n",
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" # 使用 CPU\n",
    "IMAGE_WIDTH=128\n",
    "IMAGE_HEIGHT=128\n",
    "IMAGE_SIZE=(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "IMAGE_CHANNELS=3\n",
    "batch_size= 40\n",
    "# define cnn model\n",
    "def define_model():\n",
    "\t# load model\n",
    "\tmodel = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
    "\t# mark loaded layers as not trainable\n",
    "\tfor layer in model.layers:\n",
    "\t\tlayer.trainable = False\n",
    "\t# add new classifier layers\n",
    "\tflat1 = Flatten()(model.layers[-1].output)\n",
    "\tclass1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "\toutput = Dense(1, activation='sigmoid')(class1)\n",
    "\t# define new model\n",
    "\tmodel = Model(inputs=model.inputs, outputs=output)\n",
    "\t# compile model\n",
    "\topt = SGD(lr=0.001, momentum=0.9)\n",
    "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\treturn model\n",
    " \n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history):\n",
    "    # plot loss\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Cross Entropy Loss')\n",
    "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    # plot accuracy\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Classification Accuracy')\n",
    "    pyplot.plot(history.history['acc'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_acc'], color='orange', label='test')\n",
    "    pyplot.show()\n",
    "    # save plot to file\n",
    "    filename = sys.argv[0].split('/')[-1]\n",
    "    print(filename)\n",
    "    pyplot.savefig(filename + '_plot.png')\n",
    "    pyplot.close()\n",
    " \n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness():\n",
    "    # define model\n",
    "    model = define_model()\n",
    "    # create data generator\n",
    "    datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "    # prepare iterator\n",
    "    train_it = datagen.flow_from_directory('./final-exam-data/data/kaggle_dogcat/train/',\n",
    "        class_mode='binary', batch_size=64, target_size=(224, 224))\n",
    "    test_it = datagen.flow_from_directory('./final-exam-data/data/kaggle_dogcat/test/',\n",
    "        class_mode='binary', batch_size=64, target_size=(224, 224))\n",
    "    # fit model\n",
    "    history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "        validation_data=test_it, validation_steps=len(test_it), epochs=50, verbose=0)\n",
    "    # evaluate model\n",
    "    _, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
    "    print('> %.3f' % (acc * 100.0))\n",
    "    test_filenames = os.listdir(\"./final-exam-data/data/kaggle_dogcat/test\")\n",
    "    test_df = pd.DataFrame({\n",
    "        'filename': test_filenames\n",
    "    })\n",
    "    nb_samples = test_df.shape[0]\n",
    "    test_gen = ImageDataGenerator(rescale=1./255)\n",
    "    test_generator = test_gen.flow_from_dataframe(\n",
    "        test_df, \n",
    "        \"./final-exam-data/data/kaggle_dogcat/test\", \n",
    "        x_col='filename',\n",
    "        y_col=None,\n",
    "        class_mode=None,\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False\n",
    "    )\n",
    "    predict = model.predict_generator(test_generator, steps=np.ceil(nb_samples/batch_size))\n",
    "    print(predict)\n",
    "    # learning curves\n",
    "    summarize_diagnostics(history)\n",
    " \n",
    "# entry point, run the test harness\n",
    "run_test_harness()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
